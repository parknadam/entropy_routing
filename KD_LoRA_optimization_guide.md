# KD-LoRA ì„±ëŠ¥ ìµœì í™” ê°€ì´ë“œ

## ğŸ“Š ë¬¸ì œ ë¶„ì„

### ì‹¤í—˜ ê²°ê³¼ ë¹„êµ
```
ì‹¤í—˜ 1 (lr=2e-4, r=8, Î±=16, epoch=1):
  [A] LoRA ppl=18.876 âœ… ì¢‹ìŒ

ì‹¤í—˜ 2 (lr=1e-4, r=16, Î±=32, epoch=2):
  [A] LoRA ppl=19.089 âŒ ë” ë‚˜ì¨
```

### ì„±ëŠ¥ ì €í•˜ ì›ì¸
1. **Learning Rate ë„ˆë¬´ ë‚®ìŒ**: 1e-4ëŠ” KD-LoRAì— ë¶€ì¡±
2. **Rank ì¦ê°€ â†’ ë” ë§ì€ í•™ìŠµ í•„ìš”**: Epoch 2ë¡œëŠ” ë¶€ì¡±
3. **Batch Size ë³€ê²½ íš¨ê³¼**: 1Ã—32ê°€ 4Ã—8ë³´ë‹¤ ì•ˆì •ì ì¼ ìˆ˜ ìˆìŒ
4. **KD alpha 0.1**: Teacher ì˜í–¥ë ¥ì´ ì•½í•¨

---

## ğŸ¯ ê¶Œì¥ ì‹¤í—˜ ìˆœì„œ

### 1ï¸âƒ£ ê¸°ì¤€ì„  ì¬í˜„ (ê°€ì¥ ë¨¼ì €!)
```bash
python -m prune_lora.optimized_kd_lora \
  --base_dir ./7b_results/pruning/A \
  --bundles_dir ./7b_results/pruning/bundles \
  --stage 1 \
  --out_adapters ./exp1_baseline \
  --qa_dataset squad \
  --max_samples 20000 \
  --max_eval_samples 8000 \
  --seq_len 1024 \
  --lr 2e-4 \
  --epochs 1 \
  --bs 1 \
  --grad_acc 32 \
  --lora_r 8 \
  --lora_alpha 16 \
  --use_kd \
  --teacher_model meta-llama/Llama-2-7b-chat-hf \
  --teacher_4bit \
  --teacher_device cuda:1 \
  --kd_alpha 0.1 \
  --kd_T 2.0
```
**ëª©í‘œ**: PPL < 19.0

---

### 2ï¸âƒ£ Learning Rate ì¦ê°€ (ì¦‰ì‹œ ê°œì„  ê°€ëŠ¥)
```bash
python -m prune_lora.optimized_kd_lora \
  --base_dir ./7b_results/pruning/A \
  --bundles_dir ./7b_results/pruning/bundles \
  --stage 1 \
  --out_adapters ./exp2_higher_lr \
  --qa_dataset squad \
  --max_samples 20000 \
  --max_eval_samples 8000 \
  --seq_len 1024 \
  --lr 3e-4 \
  --epochs 1 \
  --bs 1 \
  --grad_acc 32 \
  --lora_r 8 \
  --lora_alpha 16 \
  --use_kd \
  --teacher_model meta-llama/Llama-2-7b-chat-hf \
  --teacher_4bit \
  --teacher_device cuda:1 \
  --kd_alpha 0.1 \
  --kd_T 2.0
```
**ì˜ˆìƒ**: PPL 17~18 (ê°œì„ !)

---

### 3ï¸âƒ£ Epoch ì¦ê°€ (ë” ì¶©ë¶„í•œ í•™ìŠµ)
```bash
python -m prune_lora.optimized_kd_lora \
  --base_dir ./7b_results/pruning/A \
  --bundles_dir ./7b_results/pruning/bundles \
  --stage 1 \
  --out_adapters ./exp3_more_epochs \
  --qa_dataset squad \
  --max_samples 20000 \
  --max_eval_samples 8000 \
  --seq_len 1024 \
  --lr 2e-4 \
  --epochs 3 \
  --bs 1 \
  --grad_acc 32 \
  --lora_r 8 \
  --lora_alpha 16 \
  --use_kd \
  --teacher_model meta-llama/Llama-2-7b-chat-hf \
  --teacher_4bit \
  --teacher_device cuda:1 \
  --kd_alpha 0.1 \
  --kd_T 2.0
```
**ì˜ˆìƒ**: PPL 16~17 (í° ê°œì„ !)

---

### 4ï¸âƒ£ KD Alpha ì¦ê°€ (Teacher ì˜í–¥ë ¥ ê°•í™”)
```bash
python -m prune_lora.optimized_kd_lora \
  --base_dir ./7b_results/pruning/A \
  --bundles_dir ./7b_results/pruning/bundles \
  --stage 1 \
  --out_adapters ./exp4_higher_alpha \
  --qa_dataset squad \
  --max_samples 20000 \
  --max_eval_samples 8000 \
  --seq_len 1024 \
  --lr 2e-4 \
  --epochs 1 \
  --bs 1 \
  --grad_acc 32 \
  --lora_r 8 \
  --lora_alpha 16 \
  --use_kd \
  --teacher_model meta-llama/Llama-2-7b-chat-hf \
  --teacher_4bit \
  --teacher_device cuda:1 \
  --kd_alpha 0.3 \
  --kd_T 2.0
```
**ì˜ˆìƒ**: PPL 17~18 (KD íš¨ê³¼ ì¦ê°€)

---

### 5ï¸âƒ£ ìµœì  ì¡°í•© (ê°•ë ¥ ì¶”ì²œ! ğŸŒŸ)
```bash
python -m prune_lora.optimized_kd_lora \
  --base_dir ./7b_results/pruning/A \
  --bundles_dir ./7b_results/pruning/bundles \
  --stage 1 \
  --out_adapters ./exp5_optimal \
  --qa_dataset squad \
  --max_samples 20000 \
  --max_eval_samples 8000 \
  --seq_len 1024 \
  --lr 3e-4 \
  --epochs 2 \
  --bs 1 \
  --grad_acc 32 \
  --lora_r 8 \
  --lora_alpha 16 \
  --use_kd \
  --teacher_model meta-llama/Llama-2-7b-chat-hf \
  --teacher_4bit \
  --teacher_device cuda:1 \
  --kd_alpha 0.2 \
  --kd_T 2.0
```
**ì˜ˆìƒ**: PPL 15~16 (ìµœê³  ì„±ëŠ¥!)

---

### 6ï¸âƒ£ Rank 16 (ì¶©ë¶„í•œ í•™ìŠµ ì‹œ)
```bash
python -m prune_lora.optimized_kd_lora \
  --base_dir ./7b_results/pruning/A \
  --bundles_dir ./7b_results/pruning/bundles \
  --stage 1 \
  --out_adapters ./exp6_rank16 \
  --qa_dataset squad \
  --max_samples 20000 \
  --max_eval_samples 8000 \
  --seq_len 1024 \
  --lr 2e-4 \
  --epochs 4 \
  --bs 1 \
  --grad_acc 32 \
  --lora_r 16 \
  --lora_alpha 32 \
  --use_kd \
  --teacher_model meta-llama/Llama-2-7b-chat-hf \
  --teacher_4bit \
  --teacher_device cuda:1 \
  --kd_alpha 0.2 \
  --kd_T 2.0
```
**ì˜ˆìƒ**: PPL 15~17 (Epoch 4 í•„ìš”!)

---

### 7ï¸âƒ£ Temperature ì¡°ì • (ì„ íƒì )
```bash
python -m prune_lora.optimized_kd_lora \
  --base_dir ./7b_results/pruning/A \
  --bundles_dir ./7b_results/pruning/bundles \
  --stage 1 \
  --out_adapters ./exp7_temp3 \
  --qa_dataset squad \
  --max_samples 20000 \
  --max_eval_samples 8000 \
  --seq_len 1024 \
  --lr 2e-4 \
  --epochs 1 \
  --bs 1 \
  --grad_acc 32 \
  --lora_r 8 \
  --lora_alpha 16 \
  --use_kd \
  --teacher_model meta-llama/Llama-2-7b-chat-hf \
  --teacher_4bit \
  --teacher_device cuda:1 \
  --kd_alpha 0.1 \
  --kd_T 3.0
```
**íš¨ê³¼**: Softer targets (ë¯¸ì„¸ ì¡°ì •ìš©)

---

## ğŸ”¥ ë¹ ë¥¸ ê°œì„ ì„ ìœ„í•œ TOP 3 ì¶”ì²œ

### ğŸ¥‡ 1ìœ„: ì‹¤í—˜ 5 (ìµœì  ì¡°í•©)
- **LR ì¦ê°€** + **Epoch ì¦ê°€** + **KD alpha ì¦ê°€**
- ê°€ì¥ ë¹ ë¥´ê³  í™•ì‹¤í•œ ê°œì„  ì˜ˆìƒ

### ğŸ¥ˆ 2ìœ„: ì‹¤í—˜ 3 (ë” ë§ì€ Epoch)
- ë‹¨ìˆœí•˜ì§€ë§Œ íš¨ê³¼ì 
- Epoch 3ë§Œìœ¼ë¡œë„ í° ê°œì„ 

### ğŸ¥‰ 3ìœ„: ì‹¤í—˜ 2 (LR ì¦ê°€)
- ê°€ì¥ ë¹ ë¥¸ ì‹¤í—˜ (Epoch 1)
- ì¦‰ì‹œ ê°œì„  í™•ì¸ ê°€ëŠ¥

---

## ğŸ“ˆ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì˜í–¥ë„

| íŒŒë¼ë¯¸í„° | í˜„ì¬ê°’ | ê¶Œì¥ê°’ | ì˜í–¥ë„ |
|---------|--------|--------|--------|
| **Learning Rate** | 1e-4 | 2e-4 ~ 3e-4 | ğŸ”¥ğŸ”¥ğŸ”¥ ë†’ìŒ |
| **Epochs** | 2 | 2~4 | ğŸ”¥ğŸ”¥ğŸ”¥ ë†’ìŒ |
| **KD Alpha** | 0.1 | 0.2~0.3 | ğŸ”¥ğŸ”¥ ì¤‘ê°„ |
| **LoRA Rank** | 16 | 8 (íš¨ìœ¨) or 16 (ì„±ëŠ¥) | ğŸ”¥ğŸ”¥ ì¤‘ê°„ |
| **Temperature** | 2.0 | 2.0~3.0 | ğŸ”¥ ë‚®ìŒ |
| **Batch Size** | 4Ã—8 | 1Ã—32 | ğŸ”¥ ë‚®ìŒ |

---

## ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸

1. **Rank â‰  ë¬´ì¡°ê±´ ì¢‹ìŒ**: Rank 8ì´ 16ë³´ë‹¤ íš¨ìœ¨ì ì¼ ìˆ˜ ìˆìŒ
2. **LRì€ ì¶©ë¶„íˆ ë†’ì—¬ì•¼**: KD-LoRAëŠ” 2e-4 ~ 3e-4 í•„ìš”
3. **Rank ì¦ê°€ ì‹œ Epoch ì¦ê°€ í•„ìˆ˜**: 2ë°° rank â†’ 2ë°° epoch
4. **KD AlphaëŠ” 0.2~0.3 ê¶Œì¥**: Teacher ì§€ì‹ í™œìš© ì¦ê°€
5. **Batch SizeëŠ” 1Ã—32 ìœ ì§€**: ë” ì•ˆì •ì ì¸ gradient

---

## ğŸ“ ì´ë¡ ì  ë°°ê²½

### KD-LoRA Loss
```
Loss = Î± Ã— KD_soft + (1-Î±) Ã— CE_hard

Î± = 0.1 â†’ Teacher 10%, Hard labels 90%
Î± = 0.3 â†’ Teacher 30%, Hard labels 70%
```

### Rankì™€ íŒŒë¼ë¯¸í„° ìˆ˜
```
Rank 8:  ~2.9M params
Rank 16: ~5.8M params (2ë°°)
â†’ í•™ìŠµ ì‹œê°„ë„ 2ë°° í•„ìš”!
```

### Learning Rate ì„ íƒ
```
LoRA: 1e-4 ~ 5e-4 (ì¼ë°˜ì )
KD-LoRA: 2e-4 ~ 3e-4 (soft + hard ë™ì‹œ í•™ìŠµ)
```

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘ (ë³µë¶™ìš©)

**ê°€ì¥ ì¶”ì²œí•˜ëŠ” ëª…ë ¹ì–´:**
```bash
python -m prune_lora.optimized_kd_lora \
  --base_dir ./7b_results/pruning/A \
  --bundles_dir ./7b_results/pruning/bundles \
  --stage 1 \
  --out_adapters ./best_result \
  --qa_dataset squad \
  --max_samples 20000 \
  --max_eval_samples 8000 \
  --seq_len 1024 \
  --lr 3e-4 \
  --epochs 2 \
  --bs 1 \
  --grad_acc 32 \
  --lora_r 8 \
  --lora_alpha 16 \
  --use_kd \
  --teacher_model meta-llama/Llama-2-7b-chat-hf \
  --teacher_4bit \
  --teacher_device cuda:1 \
  --kd_alpha 0.2 \
  --kd_T 2.0
```

**ì˜ˆìƒ PPL: 15~16 (ê¸°ì¡´ 18.9ì—ì„œ í¬ê²Œ ê°œì„ !)**